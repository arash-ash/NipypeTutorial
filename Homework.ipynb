{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| <span style=\"font-size:larger;\">PSYC 521 Principles of Functional Magnetic Resonance Imaging</span> |\n",
    "|:-------------------------------------------------------------------------------------------------------:|\n",
    "| **GLM Analysis Homework Assignemt** |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Assignemt\n",
    "You shall create and run a GLM analysis workflow with *Nipye* library as shown in the class and deomostrated in this [Notebook](analysis_pipeline.ipynb). However, to make your job eaiser, we provided the preproced functional images in the **datasink** directory so you don't have to run the preprocessing workflow.\n",
    "\n",
    "We have divided the assignemt into following sections which consists of tasks that you will complete and explain.\n",
    "\n",
    "1. [Imports of modules](#Imports)\n",
    "2. [Specify Nodes for the main workflow](#Specify-Nodes-for-the-main-workflow)\n",
    "3. [Specify GLM contrasts](#Specify-GLM-contrasts)\n",
    "4. [Specify GLM Model](#Specify-GLM-Model)\n",
    "5. [Specify input and output stream\n",
    "](#Specify-input-and-output-stream)\n",
    "6. [Specify Workflow](#Specify-Workflow)\n",
    "7. [Visualize the workflow](#Visualize-the-workflow)\n",
    "8. [Run the Workflow](#Run-the-Workflow)\n",
    "9. [Results](#Results)\n",
    "\n",
    "You will be graded based on your **code** and **outputs** and **answers** to the questions. So don't forget to add comments so that we know it is your work and **Do not share your code!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "First, we need to import all modules we later want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Nodes for the main workflow\n",
    "Initiate all the different interfaces (represented as nodes) that you want to use in your workflow.\n",
    "You should use these ones\n",
    "1. Extract onset times of stimuli from TVA file\n",
    "2. Specify the model (TR, high pass filter, onset times, etc.)\n",
    "3. Specify contrasts to compute\n",
    "4. Estimate contrasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify GLM contrasts\n",
    "Define your contrasts similar to how it is defined in the [Notebook](analysis_pipeline.ipynb).\n",
    "\n",
    "**Task**: add a contrast that shows left **and** right activations ( i.e., a conjunction contrast)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify GLM Model\n",
    "The next step is now to get information such as stimuli onset, duration and other regressors into the GLM model. For this we need to create a helper function, in our case called ``subjectinfo``.\n",
    "\n",
    "**Note that since the helper function will be defined as a node, all imports and variables should be redefined inside it.**\n",
    "\n",
    "**Task**: Define this function such that `B_first` is only 8 secs and remaining 12 secs is another `B` block. As we discussed in the class, the expeirment is designed as such but Cem and Arash misunderstood it!\n",
    "Note that you need to modify for **duration** and **onset** times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify input and output stream\n",
    "\n",
    "Specify where the input data can be found & where and how to save the output data.\n",
    "\n",
    "**Task**: You need to change the file templates according to the new naming convention and location of the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify Workflow\n",
    "Create a workflow and connect the interface nodes and the I/O stream to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the workflow\n",
    "\n",
    "visualize the workflow with both the simple and detailed graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Run the Workflow\n",
    "\n",
    "Now that everything is ready, we can run the 1st-level analysis workflow. Change ``n_procs`` to the number of jobs/cores you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "Calculuate the T and F thresholds by applying Bonferroni familywise error correction(FWE) such that it is equivalent to a corrected p=0.05 threshold.\n",
    "\n",
    "To apply Bonferroni FWE, simply divide the desired p-threshold by the number of tests (i.e., number of masked voxel), and youâ€™ll maintain correct control over the FWE rate.\n",
    "\n",
    "Note that you can write `LaTex` equations like this:\n",
    "$$ e^{j\\pi}-1=0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Let's look at the contrasts that we've just computed using the anatomical coregistration.\n",
    "\n",
    "**Task**: Plot all the contrasts for each run with the calculated thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "What differences do you see between the F and correspoding T contrast results? What is the difference between T and F contrasts in general? - can you explain it with the difference between athiest and agnostic :D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Interpret the results with your expectation and previous results obtained in the [Notebook](analysis_pipeline.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally** you can export your notebook from File and Export Notebook As *LaTex* and generate a fancy PDF report to submit to Moodle.\n",
    "\n",
    "Feel free to contact Arash for clarifications via his email:\n",
    "arash.ashrafnejad@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
